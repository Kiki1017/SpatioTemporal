\section{MCMC} \label{app:MCMC}
The following is an example of estimation using the
 Metropolis-Hastings algorithm \citep{Metropolis53,Hastings70}.

\subsection{Load Data}
Let us first load relevant libraries and data.
\vspace*{-0.5\baselineskip}
\begin{verbatim}
##Load the spatio-temporal package
library(SpatioTemporal)
##And additional packages for plotting
library(plotrix) 

##load data
data(mesa.data.model)
##...and optimisation results
data(mesa.data.res)
\end{verbatim}

\subsection{Running the MCMC}
In addition to the standard model fitting described in 
\autoref{sec:par_estimation} the model (and parameter uncertainties) 
can be estimated using Metropolis-Hastings.

Here we run an the MCMC starting at the mode found in
\autoref{sec:par_estimation} and using a proposal matrix based on the
Hessian, as suggested in \citet{Roberts97}.
\vspace*{-0.5\baselineskip}
\begin{verbatim}
##Extract parameters
par <- mesa.data.res$par.est$res.best$par.all
##and Hessian
H <- mesa.data.res$par.est$res.best$hessian.all
##parameter uncertainty
par.sd <- sqrt(diag(solve(-H)))

if(FALSE){
  ##run the MCMC, this may take a while...
  MCMC.res <- run.MCMC(par, mesa.data.model, N = 5000, 
                       Hessian.prop = H, silent = FALSE)
}else{
  ##Get the precomputed results instead.
  MCMC.res <- mesa.data.res$MCMC.res
}
\end{verbatim}
%$

\subsection{Results}
Having run the MCMC algorithm for the model we now
investigate the results.

\subsection{Studying the Results}
We start by looking at the components of the result structure,
and some summaries of the results.
\vspace*{-0.5\baselineskip}
\begin{verbatim}
##components of the MCMC results
names(MCMC.res)

##The acceptance probability (alpha) for each step 
##in the Metropolis-Hastings algorithm.
summary(MCMC.res$acceptance)

##The MCMC-estimated parameters
summary(MCMC.res$par)
\end{verbatim}

\subsubsection{Plotting the Results}
Having studied the elements of the result structure we now plot the 
parameter tracks and MCMC estimates of the parameter densities.
\vspace*{-0.5\baselineskip}
\begin{verbatim}
##MCMC tracks for four of the parameters
par(mfrow=c(4,1),mar=c(2,2,2.5,.5))
for(i in c(4,9,13,15)){
  plot(MCMC.res$par[,i], ylab="", xlab="", type="l",
       main=colnames(MCMC.res$par)[i])
}

##And estimated densities for the log-covariance parameters.
##The red line is the approximate normal distribution given by
##the maximum-likelihood estimates, e.g. ML-estimate and 
##standard deviation from the observed information matrix.
par(mfrow=c(3,3),mar=c(4,4,2.5,.5))
for(i in 9:17){
  x <- sort(unique(MCMC.res$par[,i]))
  y <- dnorm(x, mean=par[i],sd=par.sd[i])
  dens <- density(MCMC.res$par[,i])
  plot(dens,ylim=c(0,max(c(dens$y,y))),main=names(par)[i])
  lines(x,y,col=2)
}
\end{verbatim}
%$
The large uncertainties (and bad mixing) for some of the 
log-covariance parameters are not unexpected. Recall that we only
have 25 locations to base the estimates of the range and sill for
the $\beta$-fields on (see \autoref{sec:evaluating_results}). For 
the residual $\nu$-fields, on the other hand, the estimates are
essentially based on $T=280$ replicates of the residual field;
implying that the estimates of range, sill and nugget for the 
residual field are much more certain.
